{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexa-10-hp-search-lstm-glove.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX84w0ZPCwzM"
      },
      "source": [
        "# Notebook to fine-tune the LSTM-GloVe model. \r\n",
        "We used the Keras [blog post](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) explaining how to use pretrained word embeddings in a Keras model when creating this notebook.\r\n",
        "\r\n",
        "This notebook assumes that you have the [preprocessed dataset](https://drive.google.com/file/d/11W4I3tqU7bOsbLLHlcJ66fqHXGpygmF9/view) in the \"/content\" folder. It also assumes that you have the [pickled GloVe embedding matrices](https://mcgill-my.sharepoint.com/personal/alexa_hernandez_mail_mcgill_ca/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Falexa%5Fhernandez%5Fmail%5Fmcgill%5Fca%2FDocuments%2FGloVe&originalPath=aHR0cHM6Ly9tY2dpbGwtbXkuc2hhcmVwb2ludC5jb20vOmY6L2cvcGVyc29uYWwvYWxleGFfaGVybmFuZGV6X21haWxfbWNnaWxsX2NhL0V2allBS1JnaV9SR3FYYVpnZXZnNUxNQm51VHIzQkJwYjJaRDVGZkpfN2U4MlE_cnRpbWU9Rm1OcHladWcyRWc) in the \"/content\" folder.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCnIgGRIHBv6"
      },
      "source": [
        "## Load Data and Prepare Label Index\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-dNbS-g-qmw",
        "outputId": "bdc85990-43b9-44b2-9c9c-703dae4faca1"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Load data\r\n",
        "df = pd.read_csv(\"/content/scraped-lyrics-v2-preprocessed.csv\")\r\n",
        "lyrics = df.lyrics.tolist()\r\n",
        "\r\n",
        "# Generate genres index to map label names to numeric ids\r\n",
        "genres = df.category.tolist()\r\n",
        "labels_index = {}\r\n",
        "labels = []\r\n",
        "idx = 0\r\n",
        "\r\n",
        "for g in genres:\r\n",
        "  if g not in labels_index:\r\n",
        "    labels_index[g] = idx\r\n",
        "    idx += 1\r\n",
        "  labels.append(labels_index[g])\r\n",
        " \r\n",
        "print(f\"Labels index: {labels_index}\")\r\n",
        "print(f\"Labels: {labels[:10]}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels index: {'Hard Rock': 0, 'Heavy Metal': 1, 'Hip Hop': 2, 'Indie': 3, 'Rock': 4, 'R&B': 5, 'Soul Music': 6, 'Pop': 7, 'Country': 8, 'Rock Alternativo': 9}\n",
            "Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vyX3F9lHHXa"
      },
      "source": [
        "## Tokenize Lyrics \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3oqmbciAMOK",
        "outputId": "514aeaa2-20af-456c-b175-6cd8d3e81f1b"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "tokenizer = Tokenizer(num_words=20000)\r\n",
        "tokenizer.fit_on_texts(lyrics)\r\n",
        "sequences = tokenizer.texts_to_sequences(lyrics)\r\n",
        "\r\n",
        "word_index = tokenizer.word_index\r\n",
        "print(f\"Found {len(word_index)} unique tokens.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 108740 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6K9IHF1HO_i"
      },
      "source": [
        "## Pad Lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R21NfM0nBKCt",
        "outputId": "fa15625c-081d-4ce2-ee7d-ed2e7a709808"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "data = pad_sequences(sequences, maxlen=600)\r\n",
        "labels = to_categorical(np.asarray(labels))\r\n",
        "print(f\"Shape of data tensor: {data.shape}\")\r\n",
        "print(f\"Shape of label tensor: {labels.shape}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (58719, 600)\n",
            "Shape of label tensor: (58719, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR0EprsbHSoj"
      },
      "source": [
        "## Split data into train-val-test subsets\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6qxZf1kDw_K",
        "outputId": "2212c765-dee3-42bb-e5ed-9689de599b2f"
      },
      "source": [
        "# split the data into a training set and a validation set\r\n",
        "indices = np.arange(data.shape[0])\r\n",
        "np.random.shuffle(indices)\r\n",
        "data = data[indices]\r\n",
        "labels = labels[indices]\r\n",
        "train_end = int(0.7 * data.shape[0])\r\n",
        "val_end = int(0.85 * data.shape[0])\r\n",
        "\r\n",
        "x_train = data[:train_end]\r\n",
        "y_train = labels[:train_end]\r\n",
        "x_val = data[train_end:val_end]\r\n",
        "y_val = labels[train_end:val_end]\r\n",
        "x_test = data[val_end:]\r\n",
        "y_test = labels[val_end:]\r\n",
        "\r\n",
        "print(f\"{len(x_train)} training samples, {len(x_val)} validation samples and {len(x_test)} test samples.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41103 training samples, 8808 validation samples and 8808 test samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao6uKh0XHe8c"
      },
      "source": [
        "## Prepare embedding layers for each dimension (e.g., 50, 100, 200, 300)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_npZlKwCt32J",
        "outputId": "77e88fd2-7255-4367-b5ff-24cd454333a3"
      },
      "source": [
        "!pip install pickle5"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5jPiG6aG-Dk",
        "outputId": "91a28640-f0b8-4f90-ca9e-f7a6077ca8a1"
      },
      "source": [
        "# Prepare embeddings layers\r\n",
        "import pickle5 as pickle \r\n",
        "\r\n",
        "\r\n",
        "def load_embedding_index(dim):\r\n",
        "  \"\"\"Loads the pickled embedding matrix corresponding to the pretrained GloVe embeddings with the inputted dimension.\"\"\"\r\n",
        "  with open(f\"/content/glove.6B.{dim}d.pickle\", \"rb\") as f:\r\n",
        "    embedding_index = pickle.load(f)\r\n",
        "  return embedding_index\r\n",
        "\r\n",
        "\r\n",
        "def compute_embedding_layer(word_index, embedding_index, dim):\r\n",
        "  \"\"\"Computes the embedding layers for the given word and embedding index.\"\"\"\r\n",
        "  embedding_matrix = np.zeros((len(word_index) + 1, dim))\r\n",
        "  for word, i in word_index.items():\r\n",
        "    embedding_vector = embedding_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "        # words not found in embedding index will be all-zeros.\r\n",
        "        embedding_matrix[i] = embedding_vector\r\n",
        "  return embedding_matrix\r\n",
        "\r\n",
        "# Acceptable embedding dimensions \r\n",
        "dims = [50, 100, 200, 300]\r\n",
        "\r\n",
        "# Load the embedding index of each dimension\r\n",
        "embedding_indices = {dim: load_embedding_index(dim) for dim in dims}\r\n",
        "print(f\"Loaded embedding index for the following dimensions: {embedding_indices.keys()}\")\r\n",
        "\r\n",
        "# Compute embedding layer for each dimension\r\n",
        "embedding_matrices = {dim: compute_embedding_layer(word_index, embedding_indices[dim], dim) for dim in dims}\r\n",
        "print(f\"Computed embedding matrix for the following dimensions: {embedding_matrices.keys()}\")\r\n",
        "print(f\"The embedding matrix for dimension 50 is {embedding_matrices[50]}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded embedding index for the following dimensions: dict_keys([50, 100, 200, 300])\n",
            "Computed embedding matrix for the following dimensions: dict_keys([50, 100, 200, 300])\n",
            "The embedding matrix for dimension 50 is [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.41800001  0.24968    -0.41242    ... -0.18411    -0.11514\n",
            "  -0.78580999]\n",
            " [ 0.11891     0.15255    -0.082073   ... -0.57511997 -0.26671001\n",
            "   0.92120999]\n",
            " ...\n",
            " [-0.56676    -1.09870005  0.39249    ... -0.0083835  -0.14105\n",
            "  -0.43687999]\n",
            " [ 0.66856003  0.53061998 -2.50189996 ...  0.51340997 -1.22749996\n",
            "  -0.31600001]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZsCrBS2bsOG"
      },
      "source": [
        "## Build LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pefO4MYCKaft"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Embedding, Dense, LSTM, Dropout\r\n",
        "\r\n",
        "\r\n",
        "def build_model(word_index, labels_index, embedding_dim, embedding_matrix, hidden_units, dropout):\r\n",
        "  \"\"\"Returns LSTM model with inputted configuration.\"\"\"\r\n",
        "  model = Sequential() \r\n",
        "  model.add(Embedding(\r\n",
        "      len(word_index) + 1, \r\n",
        "      embedding_dim,\r\n",
        "      weights=[embedding_matrix],\r\n",
        "      input_length=600,\r\n",
        "      trainable=False))\r\n",
        "  model.add(LSTM(units=hidden_units)) \r\n",
        "  model.add(Dropout(dropout))\r\n",
        "  model.add(Dense(len(labels_index), activation='softmax'))\r\n",
        "  model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer='rmsprop',\r\n",
        "              metrics=['acc']) \r\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB73caIwbzGr"
      },
      "source": [
        "## Fine-tune LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGegJvUZbofX",
        "outputId": "f7b12635-d060-4276-f65e-61c074894082"
      },
      "source": [
        "# Hyperparameter values to search over\r\n",
        "hidden_units = [50, 75, 100]\r\n",
        "dropouts = [0.10, 0.20, 0.30]\r\n",
        "embedding_dims = [50, 100, 200, 300]\r\n",
        "best_val_acc = 0\r\n",
        "\r\n",
        "# Perform exhaustive grid search over hyperparameter values\r\n",
        "for hu in hidden_units:\r\n",
        "  for d in dropouts:\r\n",
        "    for dim in embedding_dims:\r\n",
        "      model = build_model(word_index, labels_index, dim, embedding_matrices[dim], hu, d)\r\n",
        "      print(f\"Hyperparameters: hidden units = {hu}, dropout = {d}, embedding dimension = {dim}\")\r\n",
        "      print(model.summary()) \r\n",
        "      hist = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5, batch_size=32) \r\n",
        "      score = model.evaluate(x_test, y_test, verbose=1)\r\n",
        "      print(f\"Test accuracy: {score[1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameters: hidden units = 50, dropout = 0.1, embedding dimension = 50\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 600, 50)           5437050   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 5,457,760\n",
            "Trainable params: 20,710\n",
            "Non-trainable params: 5,437,050\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 309s 240ms/step - loss: 2.1264 - acc: 0.2327 - val_loss: 2.0502 - val_acc: 0.2631\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 319s 248ms/step - loss: 1.9604 - acc: 0.3029 - val_loss: 1.8891 - val_acc: 0.3244\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 316s 246ms/step - loss: 1.8764 - acc: 0.3321 - val_loss: 1.8324 - val_acc: 0.3500\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 319s 248ms/step - loss: 1.8248 - acc: 0.3499 - val_loss: 1.8113 - val_acc: 0.3572\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 316s 246ms/step - loss: 1.7865 - acc: 0.3628 - val_loss: 1.7657 - val_acc: 0.3736\n",
            "276/276 [==============================] - 16s 58ms/step - loss: 1.7756 - acc: 0.3667\n",
            "Test accuracy: 0.3667120933532715\n",
            "Hyperparameters: hidden units = 50, dropout = 0.1, embedding dimension = 100\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 600, 100)          10874100  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 10,904,810\n",
            "Trainable params: 30,710\n",
            "Non-trainable params: 10,874,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 337s 262ms/step - loss: 2.0983 - acc: 0.2467 - val_loss: 1.9185 - val_acc: 0.3112\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 339s 264ms/step - loss: 1.9030 - acc: 0.3238 - val_loss: 1.8178 - val_acc: 0.3488\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 342s 266ms/step - loss: 1.7999 - acc: 0.3582 - val_loss: 1.7651 - val_acc: 0.3685\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 337s 262ms/step - loss: 1.7447 - acc: 0.3806 - val_loss: 1.7427 - val_acc: 0.3764\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 329s 256ms/step - loss: 1.7007 - acc: 0.3931 - val_loss: 1.7320 - val_acc: 0.3827\n",
            "276/276 [==============================] - 18s 65ms/step - loss: 1.7414 - acc: 0.3812\n",
            "Test accuracy: 0.38124433159828186\n",
            "Hyperparameters: hidden units = 50, dropout = 0.1, embedding dimension = 200\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 600, 200)          21748200  \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 50)                50200     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 21,798,910\n",
            "Trainable params: 50,710\n",
            "Non-trainable params: 21,748,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 373s 290ms/step - loss: 2.0531 - acc: 0.2662 - val_loss: 1.8781 - val_acc: 0.3265\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 373s 291ms/step - loss: 1.8347 - acc: 0.3497 - val_loss: 1.7669 - val_acc: 0.3782\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 376s 293ms/step - loss: 1.7362 - acc: 0.3800 - val_loss: 1.7174 - val_acc: 0.3903\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 379s 295ms/step - loss: 1.6741 - acc: 0.4038 - val_loss: 1.6878 - val_acc: 0.4032\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 376s 293ms/step - loss: 1.6242 - acc: 0.4236 - val_loss: 1.6778 - val_acc: 0.4099\n",
            "276/276 [==============================] - 22s 81ms/step - loss: 1.6910 - acc: 0.4017\n",
            "Test accuracy: 0.4016802906990051\n",
            "Hyperparameters: hidden units = 50, dropout = 0.1, embedding dimension = 300\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 600, 300)          32622300  \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 50)                70200     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 32,693,010\n",
            "Trainable params: 70,710\n",
            "Non-trainable params: 32,622,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 434s 338ms/step - loss: 2.0311 - acc: 0.2743 - val_loss: 2.3605 - val_acc: 0.2123\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 433s 337ms/step - loss: 1.8037 - acc: 0.3585 - val_loss: 1.7882 - val_acc: 0.3618\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 432s 336ms/step - loss: 1.7045 - acc: 0.3936 - val_loss: 1.7401 - val_acc: 0.3850\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 434s 338ms/step - loss: 1.6330 - acc: 0.4167 - val_loss: 1.6769 - val_acc: 0.4074\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 434s 338ms/step - loss: 1.5767 - acc: 0.4356 - val_loss: 1.6949 - val_acc: 0.3985\n",
            "276/276 [==============================] - 28s 100ms/step - loss: 1.7047 - acc: 0.3965\n",
            "Test accuracy: 0.3964577615261078\n",
            "Hyperparameters: hidden units = 50, dropout = 0.2, embedding dimension = 50\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 600, 50)           5437050   \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 5,457,760\n",
            "Trainable params: 20,710\n",
            "Non-trainable params: 5,437,050\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 312s 243ms/step - loss: 2.1088 - acc: 0.2424 - val_loss: 2.0038 - val_acc: 0.2917\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 320s 249ms/step - loss: 1.9559 - acc: 0.3041 - val_loss: 1.8963 - val_acc: 0.3275\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 322s 250ms/step - loss: 1.8765 - acc: 0.3310 - val_loss: 1.8254 - val_acc: 0.3518\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 319s 249ms/step - loss: 1.8244 - acc: 0.3495 - val_loss: 1.7945 - val_acc: 0.3546\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 322s 251ms/step - loss: 1.7872 - acc: 0.3646 - val_loss: 1.7705 - val_acc: 0.3681\n",
            "276/276 [==============================] - 16s 59ms/step - loss: 1.7786 - acc: 0.3663\n",
            "Test accuracy: 0.3662579357624054\n",
            "Hyperparameters: hidden units = 50, dropout = 0.2, embedding dimension = 100\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 600, 100)          10874100  \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 10,904,810\n",
            "Trainable params: 30,710\n",
            "Non-trainable params: 10,874,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 324s 252ms/step - loss: 2.0903 - acc: 0.2491 - val_loss: 1.9125 - val_acc: 0.3154\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 340s 265ms/step - loss: 1.8816 - acc: 0.3308 - val_loss: 1.8429 - val_acc: 0.3471\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 339s 263ms/step - loss: 1.7962 - acc: 0.3621 - val_loss: 1.7566 - val_acc: 0.3795\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 338s 263ms/step - loss: 1.7461 - acc: 0.3744 - val_loss: 1.7328 - val_acc: 0.3837\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 337s 262ms/step - loss: 1.7071 - acc: 0.3921 - val_loss: 1.7161 - val_acc: 0.3836\n",
            "276/276 [==============================] - 18s 66ms/step - loss: 1.7335 - acc: 0.3811\n",
            "Test accuracy: 0.38113078474998474\n",
            "Hyperparameters: hidden units = 50, dropout = 0.2, embedding dimension = 200\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 600, 200)          21748200  \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 50)                50200     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 21,798,910\n",
            "Trainable params: 50,710\n",
            "Non-trainable params: 21,748,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 379s 295ms/step - loss: 2.0513 - acc: 0.2627 - val_loss: 1.9426 - val_acc: 0.2960\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 375s 292ms/step - loss: 1.8502 - acc: 0.3393 - val_loss: 1.7838 - val_acc: 0.3638\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 375s 292ms/step - loss: 1.7596 - acc: 0.3710 - val_loss: 1.7563 - val_acc: 0.3782\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 375s 292ms/step - loss: 1.6980 - acc: 0.3965 - val_loss: 1.8370 - val_acc: 0.3441\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 375s 292ms/step - loss: 1.6534 - acc: 0.4116 - val_loss: 1.6842 - val_acc: 0.4040\n",
            "276/276 [==============================] - 23s 83ms/step - loss: 1.6877 - acc: 0.4047\n",
            "Test accuracy: 0.4047456979751587\n",
            "Hyperparameters: hidden units = 50, dropout = 0.2, embedding dimension = 300\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 600, 300)          32622300  \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 50)                70200     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 32,693,010\n",
            "Trainable params: 70,710\n",
            "Non-trainable params: 32,622,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 432s 336ms/step - loss: 2.0309 - acc: 0.2739 - val_loss: 1.8613 - val_acc: 0.3336\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 433s 337ms/step - loss: 1.8273 - acc: 0.3478 - val_loss: 1.8217 - val_acc: 0.3496\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 431s 335ms/step - loss: 1.7301 - acc: 0.3863 - val_loss: 1.7588 - val_acc: 0.3742\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 431s 336ms/step - loss: 1.6661 - acc: 0.4115 - val_loss: 1.6883 - val_acc: 0.3979\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 438s 341ms/step - loss: 1.6079 - acc: 0.4291 - val_loss: 1.6902 - val_acc: 0.4010\n",
            "276/276 [==============================] - 29s 103ms/step - loss: 1.7004 - acc: 0.4040\n",
            "Test accuracy: 0.403950959444046\n",
            "Hyperparameters: hidden units = 50, dropout = 0.3, embedding dimension = 50\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 600, 50)           5437050   \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 5,457,760\n",
            "Trainable params: 20,710\n",
            "Non-trainable params: 5,437,050\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 317s 247ms/step - loss: 2.1323 - acc: 0.2355 - val_loss: 2.0714 - val_acc: 0.2545\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 330s 257ms/step - loss: 1.9812 - acc: 0.2946 - val_loss: 2.0223 - val_acc: 0.2971\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 327s 255ms/step - loss: 1.8974 - acc: 0.3257 - val_loss: 1.8509 - val_acc: 0.3450\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 325s 253ms/step - loss: 1.8423 - acc: 0.3428 - val_loss: 1.8092 - val_acc: 0.3531\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 325s 253ms/step - loss: 1.8058 - acc: 0.3563 - val_loss: 1.7869 - val_acc: 0.3632\n",
            "276/276 [==============================] - 17s 61ms/step - loss: 1.7984 - acc: 0.3529\n",
            "Test accuracy: 0.35286104679107666\n",
            "Hyperparameters: hidden units = 50, dropout = 0.3, embedding dimension = 100\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 600, 100)          10874100  \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 10,904,810\n",
            "Trainable params: 30,710\n",
            "Non-trainable params: 10,874,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 334s 260ms/step - loss: 2.1172 - acc: 0.2401 - val_loss: 1.9335 - val_acc: 0.3079\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 337s 262ms/step - loss: 1.9178 - acc: 0.3182 - val_loss: 1.8427 - val_acc: 0.3421\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 336s 261ms/step - loss: 1.8261 - acc: 0.3507 - val_loss: 1.8309 - val_acc: 0.3504\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 335s 261ms/step - loss: 1.7679 - acc: 0.3726 - val_loss: 1.7507 - val_acc: 0.3818\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 339s 264ms/step - loss: 1.7279 - acc: 0.3849 - val_loss: 1.7215 - val_acc: 0.3874\n",
            "276/276 [==============================] - 18s 65ms/step - loss: 1.7385 - acc: 0.3803\n",
            "Test accuracy: 0.38033604621887207\n",
            "Hyperparameters: hidden units = 50, dropout = 0.3, embedding dimension = 200\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 600, 200)          21748200  \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 50)                50200     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 21,798,910\n",
            "Trainable params: 50,710\n",
            "Non-trainable params: 21,748,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 384s 299ms/step - loss: 2.0682 - acc: 0.2611 - val_loss: 1.8946 - val_acc: 0.3224\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 383s 298ms/step - loss: 1.8479 - acc: 0.3433 - val_loss: 1.7863 - val_acc: 0.3611\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 382s 297ms/step - loss: 1.7599 - acc: 0.3737 - val_loss: 1.7918 - val_acc: 0.3559\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 384s 298ms/step - loss: 1.7042 - acc: 0.3945 - val_loss: 1.6918 - val_acc: 0.3982\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 383s 298ms/step - loss: 1.6590 - acc: 0.4121 - val_loss: 1.6818 - val_acc: 0.3990\n",
            "276/276 [==============================] - 22s 81ms/step - loss: 1.6980 - acc: 0.3973\n",
            "Test accuracy: 0.39725250005722046\n",
            "Hyperparameters: hidden units = 50, dropout = 0.3, embedding dimension = 300\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 600, 300)          32622300  \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 50)                70200     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 32,693,010\n",
            "Trainable params: 70,710\n",
            "Non-trainable params: 32,622,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 451s 351ms/step - loss: 2.0420 - acc: 0.2722 - val_loss: 1.8851 - val_acc: 0.3190\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 442s 344ms/step - loss: 1.8329 - acc: 0.3471 - val_loss: 1.7581 - val_acc: 0.3816\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 441s 343ms/step - loss: 1.7328 - acc: 0.3845 - val_loss: 1.7176 - val_acc: 0.3918\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 439s 342ms/step - loss: 1.6721 - acc: 0.4056 - val_loss: 1.6810 - val_acc: 0.4045\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 444s 345ms/step - loss: 1.6245 - acc: 0.4228 - val_loss: 1.6556 - val_acc: 0.4092\n",
            "276/276 [==============================] - 28s 101ms/step - loss: 1.6754 - acc: 0.4069\n",
            "Test accuracy: 0.40690281987190247\n",
            "Hyperparameters: hidden units = 75, dropout = 0.1, embedding dimension = 50\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 600, 50)           5437050   \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 75)                37800     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                760       \n",
            "=================================================================\n",
            "Total params: 5,475,610\n",
            "Trainable params: 38,560\n",
            "Non-trainable params: 5,437,050\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 413s 321ms/step - loss: 2.0860 - acc: 0.2521 - val_loss: 1.9744 - val_acc: 0.2844\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 425s 331ms/step - loss: 1.9189 - acc: 0.3157 - val_loss: 1.8608 - val_acc: 0.3431\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 418s 325ms/step - loss: 1.8409 - acc: 0.3435 - val_loss: 1.8090 - val_acc: 0.3565\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 439s 341ms/step - loss: 1.7841 - acc: 0.3634 - val_loss: 1.7684 - val_acc: 0.3685\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 434s 338ms/step - loss: 1.7463 - acc: 0.3778 - val_loss: 1.7515 - val_acc: 0.3781\n",
            "276/276 [==============================] - 24s 88ms/step - loss: 1.7672 - acc: 0.3682\n",
            "Test accuracy: 0.3681880235671997\n",
            "Hyperparameters: hidden units = 75, dropout = 0.1, embedding dimension = 100\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 600, 100)          10874100  \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 75)                52800     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                760       \n",
            "=================================================================\n",
            "Total params: 10,927,660\n",
            "Trainable params: 53,560\n",
            "Non-trainable params: 10,874,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 441s 343ms/step - loss: 2.0652 - acc: 0.2606 - val_loss: 1.9908 - val_acc: 0.2695\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 443s 345ms/step - loss: 1.8524 - acc: 0.3411 - val_loss: 1.7948 - val_acc: 0.3633\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 442s 344ms/step - loss: 1.7708 - acc: 0.3720 - val_loss: 1.7634 - val_acc: 0.3691\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 443s 345ms/step - loss: 1.7173 - acc: 0.3876 - val_loss: 1.7240 - val_acc: 0.3834\n",
            "Epoch 5/5\n",
            "1285/1285 [==============================] - 446s 347ms/step - loss: 1.6714 - acc: 0.4032 - val_loss: 1.7832 - val_acc: 0.3676\n",
            "276/276 [==============================] - 26s 93ms/step - loss: 1.7984 - acc: 0.3648\n",
            "Test accuracy: 0.3647820055484772\n",
            "Hyperparameters: hidden units = 75, dropout = 0.1, embedding dimension = 200\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 600, 200)          21748200  \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 75)                82800     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                760       \n",
            "=================================================================\n",
            "Total params: 21,831,760\n",
            "Trainable params: 83,560\n",
            "Non-trainable params: 21,748,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1285/1285 [==============================] - 514s 400ms/step - loss: 2.0295 - acc: 0.2739 - val_loss: 1.8584 - val_acc: 0.3384\n",
            "Epoch 2/5\n",
            "1285/1285 [==============================] - 529s 412ms/step - loss: 1.8083 - acc: 0.3569 - val_loss: 1.7518 - val_acc: 0.3789\n",
            "Epoch 3/5\n",
            "1285/1285 [==============================] - 529s 411ms/step - loss: 1.7065 - acc: 0.3905 - val_loss: 1.7609 - val_acc: 0.3829\n",
            "Epoch 4/5\n",
            "1285/1285 [==============================] - 526s 409ms/step - loss: 1.6383 - acc: 0.4150 - val_loss: 1.7007 - val_acc: 0.3973\n",
            "Epoch 5/5\n",
            " 786/1285 [=================>............] - ETA: 3:14 - loss: 1.5774 - acc: 0.4381"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}